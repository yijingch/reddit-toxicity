{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snEnoaKIHAo7"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Homework 7: Deep Learning\n",
    "\n",
    "For this assignment, question 1 is worth 50 points, and question 2 is worth 40 points, for a total of 90 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file AND corresponding **HTML** file to the Canvas site.\n",
    "\n",
    "As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates: if you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuzKPRVbIZa4"
   },
   "source": [
    "### Put your name here: `Yijing Chen`\n",
    "\n",
    "### Put your uniquename here: `yijingch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MoM5xcOIbQ4"
   },
   "source": [
    "### Question 1 Comparing ML with DL (50 points)\n",
    "\n",
    "In this question, we are still exploring classifying the IMDB movie data set as we did in the lab.   You will use the different classifiers you learned in this course: (1) LinearSVC; (2) RandomForestClassifier; (3) Deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJXpYJ7OJaGc"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VOcDl-HaA7v_"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "X_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "X_test = vectorize_sequences(test_data)\n",
    "\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PunE5RENek1F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtbYQ4ePG9G5"
   },
   "source": [
    "#### Question 1(a) (10 points)\n",
    "Please use LinearSVC to train the model and return the mean accuracy on the given test data and labels. You can use the default parameteers in LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0OJbKvVCBRb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yijingch/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the training set 0.99996\n",
      "accuracy on the test set 0.83572\n"
     ]
    }
   ],
   "source": [
    "def answer_one_a():\n",
    "    from sklearn.svm import LinearSVC\n",
    "    \n",
    "    clf = LinearSVC(max_iter=2000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "\n",
    "    print(\"accuracy on the training set\", score_train)\n",
    "    print(\"accuracy on the test set\", score_test)\n",
    "\n",
    "answer_one_a()\n",
    "\n",
    "# max_iter = 2000, seems to overfit\n",
    "# also received ConvergenceWarning: Liblinear failed to converge\n",
    "# accuracy on the training set 0.99996\n",
    "# accuracy on the test set 0.83572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImowCOgQK3tb"
   },
   "source": [
    "#### Question 1(b) (10 points)\n",
    "Please use RandomForestClassifier (with random_state = 0) to train the model and return the mean accuracy on the given test data and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "haEhg85RGSS1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the training set 1.0\n",
      "accuracy on the test set 0.84384\n"
     ]
    }
   ],
   "source": [
    "def answer_one_b():\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "\n",
    "    print(\"accuracy on the training set\", score_train)\n",
    "    print(\"accuracy on the test set\", score_test)\n",
    "\n",
    "answer_one_b()\n",
    "\n",
    "# default parameter: (also overfitting)\n",
    "# accuracy on the training set 1.0\n",
    "# accuracy on the test set 0.84384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ydNcuKDMLA3"
   },
   "source": [
    "#### Question 1(c) (20 points)\n",
    "\n",
    "Please use the below architecture of the dense layers to design your model:\n",
    "one intermediate layers with 32 hidden units, \n",
    "and a second layer which will output the scalar prediction regarding the sentiment of the current review. \n",
    "\n",
    "The intermediate layer will use `relu` as its \"activation function\", \n",
    "and the final layer will use a sigmoid activation so as to output a probability \n",
    "(a score between 0 and 1, indicating how likely the sample is to have the target \"1\", i.e. how likely the review is to be positive). \n",
    "A `relu` (rectified linear unit) is a function meant to zero-out negative values, \n",
    "while a sigmoid \"squashes\" arbitrary values into the `[0, 1]` interval, thus outputting something that can be interpreted as a probability.\n",
    "\n",
    "We configure our model with the `rmsprop` optimizer and the `binary_crossentropy` loss function as we did in the lab. Note that we will \n",
    "also monitor accuracy during training.\n",
    "\n",
    "For model fitting, we train our model for 4 epochs (4 iterations over all samples in the x_train and y_train tensors), in mini-batches of 512 samples.\n",
    "\n",
    "Please return the testing accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-H3M537-ktCH"
   },
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7nEJEwy6MlXq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8301\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.2509 - accuracy: 0.9122\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1997 - accuracy: 0.9288\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9401\n",
      "782/782 [==============================] - 1s 642us/step - loss: 0.2881 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2880520522594452, 0.884440004825592]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one_c():\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, activation=\"relu\", input_shape=(10000,))) # the 1st layer with 32 hidden units, use \"relu\" to activate\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\")) # the 2nd layer using sigmoid activation\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=4, batch_size=512)\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    return results\n",
    "\n",
    "answer_one_c()\n",
    "\n",
    "# result 1:\n",
    "# Epoch 1/4\n",
    "# 49/49 [==============================] - 2s 32ms/step - loss: 0.4174 - accuracy: 0.8252\n",
    "# Epoch 2/4\n",
    "# 49/49 [==============================] - 2s 32ms/step - loss: 0.2484 - accuracy: 0.9119\n",
    "# Epoch 3/4\n",
    "# 49/49 [==============================] - 2s 32ms/step - loss: 0.1975 - accuracy: 0.9294\n",
    "# Epoch 4/4\n",
    "# 49/49 [==============================] - 2s 32ms/step - loss: 0.1696 - accuracy: 0.9408\n",
    "# 782/782 [==============================] - 2s 2ms/step - loss: 0.3061 - accuracy: 0.8771\n",
    "# [0.3060723543167114, 0.8771200180053711]\n",
    "\n",
    "# result 2:\n",
    "# Epoch 1/4\n",
    "# 49/49 [==============================] - 2s 34ms/step - loss: 0.4210 - accuracy: 0.8264\n",
    "# Epoch 2/4\n",
    "# 49/49 [==============================] - 2s 32ms/step - loss: 0.2492 - accuracy: 0.9127\n",
    "# Epoch 3/4\n",
    "# 49/49 [==============================] - 2s 33ms/step - loss: 0.1976 - accuracy: 0.9314\n",
    "# Epoch 4/4\n",
    "# 49/49 [==============================] - 2s 33ms/step - loss: 0.1683 - accuracy: 0.9422\n",
    "# 782/782 [==============================] - 2s 3ms/step - loss: 0.2934 - accuracy: 0.8834\n",
    "# [0.29340335726737976, 0.8834400177001953]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zq81A_NPRVd"
   },
   "source": [
    "#### Question 1(d) Open Question (10 points)\n",
    "Can you conclude that deep learning is better than the classic ML models on this task? If so, what do you think that helps Deep Learning perform better? If not, tells us your reasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcTU8JNvQaCa"
   },
   "source": [
    "Deep learning models apparantly achieved better results than classic ML models. I think one of the advantages of deep learning models lies in the multi-layer architecture (the neural network) that learns the feature automatically. \n",
    "\n",
    "(In addition, because of the SGD training process, I noticed that with 4 epochs, the deep learning model (sometimes) does not reach an optimal point where the loss is minimized and the accuracy is maximized, which could be the reason why the current improvements on accuracy scores is not as impressive as it should be.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3PSt7I5R6fC"
   },
   "source": [
    "## Question 2 Hyper-parameteer tunning in DL (40 points)\n",
    "\n",
    "We have shown you how to tune parameters such as training epoch in the lab. \n",
    "\n",
    "In this question, we are exploring the hyper-parameteer tuning in deep learning from the perspective of the size of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPfJlhYKTnMo"
   },
   "source": [
    "First, we divide some part of training data into valiadation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fd3GmUL4TmKO"
   },
   "outputs": [],
   "source": [
    "x_val = X_train[:10000]\n",
    "partial_x_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOGtwWvATxKi"
   },
   "source": [
    "### Question 2(a): (30 points)\n",
    "\n",
    "Follow the IMDB classification question in Question 1, we hope you design and test different neural network. You shall vary the first intermediate layer with [3, 6, 9, 12] hidden units, and the second intermediate layer with [2, 4, 6, 8] hidden units. \n",
    "\n",
    "The last layer which will output the scalar prediction regarding the sentiment of the current review. \n",
    "\n",
    "Apply the different models onto the valiadation set and return the best model with highest accuracy on the valiadation. You should three numbers, which represent the best model's number of hideen units in first, second intermediate layer, and the best accuracy. \n",
    "\n",
    "Fit the model by using the default setting in 1(c). (epochs = 4, batch_sze = 512, optimizer = rmsprop, loss = binary_crossentropy, metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybSD6iByUz3n",
    "outputId": "b0ae2037-4c98-4dec-bb97-e952833a640d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden units in the 1st layer: 3\n",
      "hidden units in the 2nd layer: 2\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6307 - accuracy: 0.6773\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5387 - accuracy: 0.7778\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4889 - accuracy: 0.8443\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4546 - accuracy: 0.8825\n",
      "782/782 [==============================] - 1s 785us/step - loss: 0.4938 - accuracy: 0.8308\n",
      "  accuracy: 0.830839991569519\n",
      "hidden units in the 1st layer: 3\n",
      "hidden units in the 2nd layer: 4\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6470 - accuracy: 0.6396\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5730 - accuracy: 0.7635\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5220 - accuracy: 0.8215\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4813 - accuracy: 0.8571\n",
      "782/782 [==============================] - 1s 782us/step - loss: 0.5016 - accuracy: 0.8225\n",
      "  accuracy: 0.8225200176239014\n",
      "hidden units in the 1st layer: 3\n",
      "hidden units in the 2nd layer: 6\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.6376 - accuracy: 0.6171\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5520 - accuracy: 0.7595\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5000 - accuracy: 0.8291\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4622 - accuracy: 0.8733\n",
      "782/782 [==============================] - 1s 755us/step - loss: 0.4929 - accuracy: 0.8478\n",
      "  accuracy: 0.847760021686554\n",
      "hidden units in the 1st layer: 3\n",
      "hidden units in the 2nd layer: 8\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6433 - accuracy: 0.6752\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5455 - accuracy: 0.8339\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4608 - accuracy: 0.8761\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3868 - accuracy: 0.8966\n",
      "782/782 [==============================] - 1s 780us/step - loss: 0.4004 - accuracy: 0.8690\n",
      "  accuracy: 0.8689600229263306\n",
      "hidden units in the 1st layer: 6\n",
      "hidden units in the 2nd layer: 2\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6795 - accuracy: 0.5988\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6356 - accuracy: 0.6685\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5839 - accuracy: 0.7423\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.5361 - accuracy: 0.8051\n",
      "782/782 [==============================] - 1s 795us/step - loss: 0.5427 - accuracy: 0.7535\n",
      "  accuracy: 0.7535200119018555\n",
      "hidden units in the 1st layer: 6\n",
      "hidden units in the 2nd layer: 4\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6593 - accuracy: 0.7587\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5707 - accuracy: 0.8570\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.8759\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4059 - accuracy: 0.8914\n",
      "782/782 [==============================] - 1s 793us/step - loss: 0.4134 - accuracy: 0.8674\n",
      "  accuracy: 0.8673999905586243\n",
      "hidden units in the 1st layer: 6\n",
      "hidden units in the 2nd layer: 6\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5344 - accuracy: 0.7799\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3488 - accuracy: 0.8931\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2647 - accuracy: 0.9201\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2149 - accuracy: 0.9307\n",
      "782/782 [==============================] - 1s 781us/step - loss: 0.2996 - accuracy: 0.8813\n",
      "  accuracy: 0.8812800049781799\n",
      "hidden units in the 1st layer: 6\n",
      "hidden units in the 2nd layer: 8\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.7524\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3705 - accuracy: 0.8919\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2766 - accuracy: 0.9177\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2226 - accuracy: 0.9303\n",
      "782/782 [==============================] - 1s 764us/step - loss: 0.3022 - accuracy: 0.8825\n",
      "  accuracy: 0.8825200200080872\n",
      "hidden units in the 1st layer: 9\n",
      "hidden units in the 2nd layer: 2\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.6778\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7984\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4798 - accuracy: 0.8551\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.8871\n",
      "782/782 [==============================] - 1s 800us/step - loss: 0.4858 - accuracy: 0.8765\n",
      "  accuracy: 0.8765199780464172\n",
      "hidden units in the 1st layer: 9\n",
      "hidden units in the 2nd layer: 4\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6131 - accuracy: 0.6837\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.8291\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.8865\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3606 - accuracy: 0.9207\n",
      "782/782 [==============================] - 1s 812us/step - loss: 0.3923 - accuracy: 0.8763\n",
      "  accuracy: 0.8763200044631958\n",
      "hidden units in the 1st layer: 9\n",
      "hidden units in the 2nd layer: 6\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5216 - accuracy: 0.7776\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3187 - accuracy: 0.9006\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2394 - accuracy: 0.9253\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1932 - accuracy: 0.9403\n",
      "782/782 [==============================] - 1s 841us/step - loss: 0.3117 - accuracy: 0.8730\n",
      "  accuracy: 0.8730400204658508\n",
      "hidden units in the 1st layer: 9\n",
      "hidden units in the 2nd layer: 8\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5789 - accuracy: 0.7402\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4185 - accuracy: 0.8856\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3189 - accuracy: 0.9179\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.9301\n",
      "782/782 [==============================] - 1s 795us/step - loss: 0.3107 - accuracy: 0.8842\n",
      "  accuracy: 0.8841599822044373\n",
      "hidden units in the 1st layer: 12\n",
      "hidden units in the 2nd layer: 2\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6010 - accuracy: 0.7181\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.8413\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4545 - accuracy: 0.8820\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4215 - accuracy: 0.9074\n",
      "782/782 [==============================] - 1s 864us/step - loss: 0.4733 - accuracy: 0.8664\n",
      "  accuracy: 0.8664399981498718\n",
      "hidden units in the 1st layer: 12\n",
      "hidden units in the 2nd layer: 4\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5619 - accuracy: 0.7582\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3677 - accuracy: 0.8946\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2720 - accuracy: 0.9226\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2160 - accuracy: 0.9375\n",
      "782/782 [==============================] - 1s 811us/step - loss: 0.3337 - accuracy: 0.8651\n",
      "  accuracy: 0.865119993686676\n",
      "hidden units in the 1st layer: 12\n",
      "hidden units in the 2nd layer: 6\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.7839\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3103 - accuracy: 0.9034\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 0.9280\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9413\n",
      "782/782 [==============================] - 1s 774us/step - loss: 0.3201 - accuracy: 0.8688\n",
      "  accuracy: 0.8687599897384644\n",
      "hidden units in the 1st layer: 12\n",
      "hidden units in the 2nd layer: 8\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4992 - accuracy: 0.7945\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3068 - accuracy: 0.9016\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2295 - accuracy: 0.9253\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1835 - accuracy: 0.9415\n",
      "782/782 [==============================] - 1s 755us/step - loss: 0.2913 - accuracy: 0.8832\n",
      "  accuracy: 0.8831999897956848\n",
      "!! best performing model !!\n",
      "hidden units in the 1st layer: 9\n",
      "hidden units in the 2nd layer: 8\n",
      "  accuracy: 0.8841599822044373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 8, 0.8841599822044373)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two_a():\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    best_first, best_second, best_res = 0, 0, 0\n",
    "\n",
    "    score_dict = {}\n",
    "    for first_layer in [3, 6, 9, 12]:\n",
    "        for second_layer in [2, 4, 6, 8]:\n",
    "            print(\"hidden units in the 1st layer:\", first_layer)\n",
    "            print(\"hidden units in the 2nd layer:\", second_layer)\n",
    "            model = models.Sequential()\n",
    "            model.add(layers.Dense(first_layer, activation=\"relu\", input_shape=(10000,)))\n",
    "            model.add(layers.Dense(second_layer, activation=\"relu\"))\n",
    "            model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\n",
    "            model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "            model.fit(partial_x_train, partial_y_train, epochs=4, batch_size=512)\n",
    "\n",
    "            score = model.evaluate(X_test, y_test)[1]\n",
    "            score_dict[(first_layer, second_layer)] = score\n",
    "            print(\"  accuracy:\", score)\n",
    "\n",
    "    best_first, best_second = max(score_dict, key=score_dict.get)\n",
    "    best_res = score_dict[(best_first, best_second)]\n",
    "    print(\"!! best performing model !!\")\n",
    "    print(\"hidden units in the 1st layer:\", best_first)\n",
    "    print(\"hidden units in the 2nd layer:\", second_layer)\n",
    "    print(\"  accuracy:\", best_res)\n",
    "\n",
    "    return best_first, best_second, best_res\n",
    "\n",
    "answer_two_a()\n",
    "\n",
    "# first run:\n",
    "# (6, 8, 0.8838000297546387)\n",
    "\n",
    "# second run:\n",
    "# (12, 6, 0.8835999965667725)\n",
    "\n",
    "# third run:\n",
    "# (9, 8, 0.8841599822044373)\n",
    "\n",
    "# these best performing models do not have the most complex neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em0olr1NX9jQ"
   },
   "source": [
    "#### Question 2(b): (10 points)\n",
    "\n",
    "According to the performance we observed for three models? Which design is best for this task? \n",
    "\n",
    "What take-away do you get from this question? Does it mean larger network improve the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6rOylRfYbHE"
   },
   "source": [
    "Based on the performance, the best performing model with an accuracy of 0.88 does not (necessarily) have the most complex neural network. I ran the program for several times and because of the stochasticity involved in the process, the best performing model is not fixed (see comments in the last code block). But, the take-away is that larger network does not always guarantee a better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PuzKPRVbIZa4"
   ],
   "name": "si670f20_hw7_yijingch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
